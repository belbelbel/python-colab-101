{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNnJS0hmWM5VLrAJbGzPEC4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/belbelbel/python-colab-101/blob/main/face_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Face Filtering\n",
        "\n",
        "In this case, you want to filter image data and detect faces within those images. You want to move the image data to the `destination` folder. Additionally, you want to crop the detected faces and save them in the `destination_for_cropped_img`."
      ],
      "metadata": {
        "id": "CZRKY4mPcUFb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dR0GZlNSYSNt"
      },
      "outputs": [],
      "source": [
        "import dlib\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source = '/content/drive/MyDrive/source_folder'\n",
        "destination = '/content/drive/MyDrive/destination'\n",
        "destination_for_cropped_img = '/content/drive/MyDrive/destination_crop'"
      ],
      "metadata": {
        "id": "bqGKy7a9Z_4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> i use dlib for face detection\n",
        "\n"
      ],
      "metadata": {
        "id": "DQv3_5kZepDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_path = './shape_predictor_68_face_landmarks.dat'\n",
        "predictor = dlib.shape_predictor(predictor_path)\n",
        "detector = dlib.get_frontal_face_detector()"
      ],
      "metadata": {
        "id": "1uU1tkoAeqMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img in os.listdir(source):\n",
        "  path = os.path.join(source, img)\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  detect = detector(gray)\n",
        "\n",
        "  if len(detect) > 1:\n",
        "    for face in detect:\n",
        "      x, y, w, h = face.left(), face.top(), face.right()-face.left(), face.bottom()-face.top()\n",
        "      face = image[y:y+h, x:x+w]\n",
        "\n",
        "    # to save images with detected faces\n",
        "    cv2.imwrite(os.path.join(destination, img), image)\n",
        "\n",
        "    # to save cropped faces that have been detected\n",
        "    cv2.imwrite(os.path.join(destination_for_cropped_img, img + '_crop'), face)"
      ],
      "metadata": {
        "id": "2bXbyWmjaF3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> The saved cropped images are in RGB format, but if you prefer to save them in grayscale, you can change :\n",
        "\n",
        "```\n",
        "face_in_gray = gray[y:y+h, x:x+w]\n",
        "cv2.imwrite(os.path.join(destination_for_cropped_img, img + '_crop'), face_in_gray)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z8RVpfW6gfJT"
      }
    }
  ]
}